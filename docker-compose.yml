# Chatbot BKSI - Docker Compose Configuration
# Run all services: docker-compose up -d
# Run specific service: docker-compose up api -d

services:
  # ============================================
  # FastAPI Backend
  # ============================================
  api:
    build:
      context: .
      target: api
    container_name: bksi-api
    ports:
      - "${API_PORT:-8000}:8000"
    env_file:
      - .env
    environment:
      - EMBEDDING_DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""
      - TORCH_DEVICE=cpu
    volumes:
      - ./data:/app/data
      - ./lancedb_data:/app/lancedb_data
      - ./logs:/app/logs
      - ./.cache:/app/.cache
      - model_cache:/root/.cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - bksi-network

  # ============================================
  # Gradio UI
  # ============================================
  gradio:
    build:
      context: .
      target: gradio
    container_name: bksi-gradio
    ports:
      - "${GRADIO_SERVER_PORT:-7860}:7860"
    env_file:
      - .env
    environment:
      - EMBEDDING_DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""
      - TORCH_DEVICE=cpu
      - GRADIO_SERVER_NAME=0.0.0.0
    volumes:
      - ./data:/app/data
      - ./lancedb_data:/app/lancedb_data
      - ./logs:/app/logs
      - ./.cache:/app/.cache
      - model_cache:/root/.cache
    restart: unless-stopped
    depends_on:
      - api
    networks:
      - bksi-network

  # ============================================
  # Streamlit UI
  # ============================================
  streamlit:
    build:
      context: .
      target: streamlit
    container_name: bksi-streamlit
    ports:
      - "${STREAMLIT_SERVER_PORT:-8501}:8501"
    env_file:
      - .env
    environment:
      - EMBEDDING_DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""
      - TORCH_DEVICE=cpu
    volumes:
      - ./data:/app/data
      - ./lancedb_data:/app/lancedb_data
      - ./logs:/app/logs
      - ./.cache:/app/.cache
      - model_cache:/root/.cache
    restart: unless-stopped
    depends_on:
      - api
    networks:
      - bksi-network

  # ============================================
  # CLI for document ingestion (run once)
  # ============================================
  ingest:
    build:
      context: .
      target: cli
    container_name: bksi-ingest
    env_file:
      - .env
    environment:
      - EMBEDDING_DEVICE=cpu
      - CUDA_VISIBLE_DEVICES=""
      - TORCH_DEVICE=cpu
    volumes:
      - ./data:/app/data
      - ./lancedb_data:/app/lancedb_data
      - ./logs:/app/logs
      - model_cache:/root/.cache
    command: ["ingest", "--data-dir", "/app/data/raw"]
    profiles:
      - tools
    networks:
      - bksi-network

# ============================================
# Networks
# ============================================
networks:
  bksi-network:
    driver: bridge

# ============================================
# Volumes
# ============================================
volumes:
  model_cache:
    name: bksi-model-cache
